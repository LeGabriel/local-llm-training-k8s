schema_version: 1
run:
  name: "gpt-wikitext"
  seed: 123
  device: "cpu"
  deterministic: true
  notes: "Small real-data GPT preset for slow integration testing."
model:
  name: "gpt"
  init: "random"
  block_size: 32
  d_model: 64
  n_layers: 2
  n_heads: 2
  d_ff: 128
  dropout: 0.0
  tie_embeddings: true
data:
  name: "hf_text"
  cache_dir: ".cache/datasets"
  num_workers: 0
  train_split: "train"
  val_split: "validation"
  dataset_name: "wikitext"
  dataset_config: "wikitext-2-raw-v1"
  text_column: "text"
trainer:
  max_steps: 40
  micro_batch_size: 4
  grad_accum_steps: 1
  lr: 0.003
  weight_decay: 0.0
  warmup_steps: 0
  max_grad_norm: 1.0
  log_every_steps: 10
  eval_every_steps: 10
  save_every_steps: 40
ddp:
  enabled: false
  backend: "gloo"
  init_method: "env://"
  timeout_sec: 1800
  find_unused_parameters: false
  rank: null
  world_size: null
  local_rank: null
  master_addr: null
  master_port: null
mlflow:
  enabled: true
  tracking_uri: "sqlite:///./mlflow.db"
  experiment: "llm-train-k8s"
  run_name: "v0.9-gpt-wikitext"
  log_models: false
logging:
  level: "INFO"
  json_output: true
  log_to_file: false
  file_name: "train.log"
output:
  root_dir: "runs"
  run_id: null
  save_config_copy: true
  save_meta_json: true
